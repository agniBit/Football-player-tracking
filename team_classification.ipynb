{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "team_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzA1cJAE16gA",
        "outputId": "e67d7486-23c7-45b4-982c-fbfa534fba70"
      },
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/football'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/football\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9bj06Ex2STB"
      },
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtULXCfq2VtG",
        "outputId": "f5f4f907-9db2-40d8-a6b4-58317c1344d5"
      },
      "source": [
        "# version of pytorch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWKy55bn2Xhb"
      },
      "source": [
        "# transformations to be applied on images\n",
        "transform = transforms.Compose([\n",
        "                                transforms.Resize((32,32)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                              ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLsPb2g47rSm"
      },
      "source": [
        "# define dataset\n",
        "trainData = torchvision.datasets.ImageFolder('./team_dataset/train', transform=transform)\n",
        "testData  = torchvision.datasets.ImageFolder('./team_dataset/test',  transform=transform)\n",
        "\n",
        "# defining trainloader and testloader\n",
        "trainloader = torch.utils.data.DataLoader(trainData, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testData, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4eGAv5Z7uTN",
        "outputId": "7ec6b249-b635-46a9-ffca-7159737b6fb0"
      },
      "source": [
        "# shape of training data\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(f'tensor shape  : {images.shape}   labels shape : {labels.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor shape  : torch.Size([64, 3, 32, 32])   labels shape : torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "NvYDOKSF8Pka",
        "outputId": "31d44ea6-48d7-424d-ef62-4d5cb2362de4"
      },
      "source": [
        "# visualizing the training images\n",
        "npimg = images[0].numpy()\n",
        "plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f56d0af10d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAglnthI8ykO"
      },
      "source": [
        "# defining the model architecture\n",
        "class Net(nn.Module):   \n",
        "  def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      self.cnn_layers = nn.Sequential(\n",
        "          # Defining a 2D convolution layer\n",
        "          nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(4),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          # Defining another 2D convolution layer\n",
        "          nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(4),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      )\n",
        "\n",
        "      self.linear_layers = nn.Sequential(\n",
        "          nn.Linear(4 * 8 * 8, 3)\n",
        "      )\n",
        "\n",
        "  # Defining the forward pass    \n",
        "  def forward(self, x):\n",
        "      x = self.cnn_layers(x)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.linear_layers(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qYlyOmXBngp",
        "outputId": "b30005a4-d008-42fc-e6af-98ead892dc68"
      },
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "# defining the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ys7QfShB6bZ",
        "outputId": "a56e160e-e471-40e1-c7af-f4343c56d285"
      },
      "source": [
        "for i in range(15):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(trainloader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training loss: 0.776624184846878\n",
            "Epoch 2 - Training loss: 0.1580103799700737\n",
            "Epoch 3 - Training loss: 0.031336510181427\n",
            "Epoch 4 - Training loss: 0.012588993646204472\n",
            "Epoch 5 - Training loss: 0.004356989450752735\n",
            "Epoch 6 - Training loss: 0.0028171444311738012\n",
            "Epoch 7 - Training loss: 0.0022559971548616886\n",
            "Epoch 8 - Training loss: 0.0013768545235507191\n",
            "Epoch 9 - Training loss: 0.0011164828087203205\n",
            "Epoch 10 - Training loss: 0.0007999803114216774\n",
            "Epoch 11 - Training loss: 0.00070559938903898\n",
            "Epoch 12 - Training loss: 0.0005358370370231568\n",
            "Epoch 13 - Training loss: 0.0005326573766069487\n",
            "Epoch 14 - Training loss: 0.0006989357993006706\n",
            "Epoch 15 - Training loss: 0.00041632394422777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3Uw_UfGCKZM",
        "outputId": "5cdfc4e9-284a-4067-961f-050afd3cbfcc"
      },
      "source": [
        "# getting predictions on test set and measuring the performance\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in testloader:\n",
        "  for i in range(len(labels)):\n",
        "    if torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "    img = images[i].view(1, 3, 32, 32)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    \n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.cpu()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 31\n",
            "\n",
            "Model Accuracy = 0.8387096774193549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOhJgXMPDcje"
      },
      "source": [
        "torch.save(model.state_dict(), './teamCategoryModel.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZPbfVMQKZrc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}